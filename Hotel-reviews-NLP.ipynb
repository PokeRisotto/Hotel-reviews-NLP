{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "serie = pd.read_csv('Hotel reviews.csv')\n",
    "df = pd.DataFrame(serie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the hotels for our business purpose\n",
    "df = df[df['Establishment Type'] == 'Hotel']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATE cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Review Date'].str.contains(\"ago\")]\n",
    "df = df[~df['Review Date'].str.contains(\"NEW\")]\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review Date'] = pd.to_datetime(df['Review Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOCATION cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Location[df.Location.isnull() == True] = 'NULL' #Assigning a NULL to the empty cell, without doing it it is difficult to work on this column of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Location = df.Location.str.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a column just with the city and not the country because we have a lot of missing values for the country so is relevant to save only the city\n",
    "for i in range(0,len(df)):\n",
    "        df.Location[i] = df.Location[i][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewieer rank CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviewer Rank'].fillna('Contributor', inplace=True)\n",
    "df['Reviewer Rank'] = df['Reviewer Rank'].map({'Contributor': 1,'Reviewer': 2,\\\n",
    "                                               'Senior Contributor': 3,'Senior Reviewer': 4, 'Top Contributor': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding the Score Breakdown into 6 different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a function to use in the below for loop\n",
    "def sorter(text):\n",
    "    text = text.strip()\n",
    "    if text == \"Value\":\n",
    "        return 0\n",
    "    elif text == \"Location\":\n",
    "        return 1\n",
    "    elif text == \"Sleep Quality\":\n",
    "        return 2\n",
    "    elif text == \"Rooms\":\n",
    "        return 3\n",
    "    elif text == \"Cleanliness\":\n",
    "        return 4\n",
    "    elif text == \"Service\":\n",
    "        return 5\n",
    "    elif text == \"Food\":\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Na\n",
    "df = df[df['Score Breakdown'].notna()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ma = np.zeros(shape = (len(df['Score Breakdown']), 8))\n",
    "\n",
    "for i in range(0,len(df['Score Breakdown'])):\n",
    "    \n",
    "    ar = df['Score Breakdown'][i].split(\";\")\n",
    "    ln = np.zeros(8)\n",
    "    for j in range(0,len(ar)):\n",
    "        k = ar[j][0:ar[j].index(':')]\n",
    "        value = ar[j][(ar[j].index(':')+1):(ar[j].index('of'))].strip()\n",
    "        ln[sorter(k)] = value\n",
    "    ma[i] = ln\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value'] = pd.Series(np.transpose(ma)[0]).astype(int)\n",
    "df['Location'] = pd.Series(np.transpose(ma)[1]).astype(int)\n",
    "df['Sleep Quality'] = pd.Series(np.transpose(ma)[2]).astype(int)\n",
    "df['Rooms'] = pd.Series(np.transpose(ma)[3]).astype(int)\n",
    "df['Cleanliness'] = pd.Series(np.transpose(ma)[4]).astype(int)\n",
    "df['Service'] = pd.Series(np.transpose(ma)[5]).astype(int)\n",
    "df['Food'] = pd.Series(np.transpose(ma)[6]).astype(int)\n",
    "del df['Score Breakdown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # Increase cell width\n",
    "display(HTML(\"<style>.rendered_html { font-size: 16px; }</style>\")) # Increase font size\n",
    "\n",
    "# Matplotlib conf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn conf\n",
    "import seaborn as sns\n",
    "sns.set_palette(sns.color_palette(\"seismic\"))\n",
    "\n",
    "# Needed Libraries\n",
    "import sys\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, ShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(raw_text):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \",raw_text) \n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\")) \n",
    "    not_stop_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in not_stop_words]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [stemmer.stem(word) for word in lemmatized]\n",
    "    \n",
    "    return( \" \".join( stemmed ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleaning the Overview\n",
    "df['clean_overview'] = df['Overview'].apply(lambda x: process_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Review\n",
    "# Cleaning the Overview\n",
    "df['clean_review'] = df['Review'].apply(lambda x: process_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target definition\n",
    "In order to define the target variable to train our NLP model we are going to use the overall rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = np.nan\n",
    "for i in range(0,len(df)):\n",
    "    if df['Star Rating'][i] > 3:\n",
    "        df['Target'][i] = 1\n",
    "    else:\n",
    "        df['Target'][i] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Target == 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
